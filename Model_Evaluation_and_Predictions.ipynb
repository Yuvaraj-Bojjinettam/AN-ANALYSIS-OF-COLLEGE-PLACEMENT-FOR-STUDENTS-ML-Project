{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOP+NSh3zpk5uimtAy2qR2g"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "kjiNA35tohuk",
        "outputId": "b99f3c65-d826-4885-e567-baa2e30071ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'SVC': SVC(), 'Decision Tree': DecisionTreeClassifier(), 'Logistic Regression': LogisticRegression(), 'Random Forest': RandomForestClassifier(n_estimators=50), 'Gradient Boosting': GradientBoostingClassifier(), 'Naive Bayes': GaussianNB(), 'KNN': KNeighborsClassifier()}\n",
            "SVC - Cross-validation Accuracy: 0.831100608720214\n",
            "Decision Tree - Cross-validation Accuracy: 0.8671735241502683\n",
            "Logistic Regression - Cross-validation Accuracy: 0.7569311686309185\n",
            "Random Forest - Cross-validation Accuracy: 0.8617767780265785\n",
            "Gradient Boosting - Cross-validation Accuracy: 0.8735793458133941\n",
            "Naive Bayes - Cross-validation Accuracy: 0.7815371925185133\n",
            "KNN - Cross-validation Accuracy: 0.8169411434006187\n",
            "Confusion Matrix:\n",
            "[[225  27]\n",
            " [ 50 292]]\n",
            "Training Accuracy: 0.9279089376053963\n",
            "Testing Accuracy: 0.8703703703703703\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nTo create graphs for the provided model evaluation results, we can visualize the cross-validation accuracies for each algorithm and the confusion matrix.\\nFirstly, let's create a bar plot to visualize the cross-validation accuracies of different algorithms:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#Project 1\n",
        "#AN ANALYSIS OF COLLEGE PLACEMENT FOR STUDENTS\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "# Load the Dataset\n",
        "dataset= pd.read_csv('/content/collegePlace.csv')\n",
        "\n",
        "#Appendix II\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer, KNNImputer\n",
        "# machine learning task\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "# import pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "# For classification task\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Preprocess the data: Encode categorical variables\n",
        "data_encoded = pd.get_dummies(dataset, drop_first=True)\n",
        "# Select variables for encoding\n",
        "X_columns = ['Age', 'Gender', 'Stream', 'Internships', 'CGPA', 'Hostel','HistoryOfBacklogs']\n",
        "# Set the target variable\n",
        "y_column = 'PlacedOrNot'\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = dataset[X_columns]\n",
        "y = dataset[y_column]\n",
        "# Preprocess the data: Encode categorical variables\n",
        "data_encoded = pd.get_dummies(dataset, drop_first=True)\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = data_encoded.drop(columns=['PlacedOrNot'])\n",
        "y = data_encoded['PlacedOrNot']\n",
        "# Perform one-hot encoding for all categorical columns\n",
        "df_encoded = pd.get_dummies(dataset, drop_first=True)\n",
        "from sklearn import preprocessing\n",
        "# Scale features\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "dataset.Gender = le.fit_transform(dataset.Gender)\n",
        "dataset.Stream = le.fit_transform(dataset.Stream)\n",
        "# Initialize LabelEncoder\n",
        "le = LabelEncoder()\n",
        "# Encode 'Gender' column\n",
        "dataset['Gender'] = le.fit_transform(dataset['Gender'])\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "scaler = preprocessing.MinMaxScaler()\n",
        "x = scaler.fit_transform(X)\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "# Scale the features\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "#APPENDIX III\n",
        "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Model evaluation using cross-validation\n",
        "models = {\n",
        "    'SVC': SVC(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=50),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "print(models)\n",
        "for name, model in models.items():\n",
        "    scores = cross_val_score(model, X, y, cv=3)\n",
        "    print(f\"{name} - Cross-validation Accuracy: {np.mean(scores)}\")\n",
        "# Train the Decision Tree model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# Predictions and evaluation\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "print(\"Training Accuracy:\", model.score(X_train, y_train))\n",
        "print(\"Testing Accuracy:\", model.score(X_test, y_test))\n",
        "'''\n",
        "To create graphs for the provided model evaluation results, we can visualize the cross-validation accuracies for each algorithm and the confusion matrix.\n",
        "Firstly, let's create a bar plot to visualize the cross-validation accuracies of different algorithms:'''\n"
      ]
    }
  ]
}